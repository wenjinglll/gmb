@misc{zheng2019gmangraphmultiattentionnetwork,
  title         = {GMAN: A Graph Multi-Attention Network for Traffic Prediction},
  author        = {Chuanpan Zheng and Xiaoliang Fan and Cheng Wang and Jianzhong Qi},
  year          = {2019},
  eprint        = {1911.08415},
  archiveprefix = {arXiv},
  primaryclass  = {eess.SP},
  url           = {https://arxiv.org/abs/1911.08415}
}
@misc{gu2024mambalineartimesequencemodeling,
  title         = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author        = {Albert Gu and Tri Dao},
  year          = {2024},
  eprint        = {2312.00752},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2312.00752}
}
@misc{dao2024transformersssmsgeneralizedmodels,
  title         = {Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality},
  author        = {Tri Dao and Albert Gu},
  year          = {2024},
  eprint        = {2405.21060},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2405.21060}
}
@phdthesis{albert2023phd,
  author    = {Albert Gu},
  school    = {Stanford University},
  title     = {Modeling sequences with structured state spaces},
  year      = {2023},
  url       = {https://purl.stanford.edu/mb976vf9362},
  publisher = {Stanford University}
}
@misc{gu2021combiningrecurrentconvolutionalcontinuoustime,
  title         = {Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers},
  author        = {Albert Gu and Isys Johnson and Karan Goel and Khaled Saab and Tri Dao and Atri Rudra and Christopher Ré},
  year          = {2021},
  eprint        = {2110.13985},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2110.13985}
}

@misc{gu2022efficientlymodelinglongsequences,
  title         = {Efficiently Modeling Long Sequences with Structured State Spaces},
  author        = {Albert Gu and Karan Goel and Christopher Ré},
  year          = {2022},
  eprint        = {2111.00396},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2111.00396}
}
@article{ju2017,
  author     = {Ju, Mingye and Zhang, Dengyin and Wang, Xuemei},
  title      = {Single image dehazing via an improved atmospheric scattering model},
  year       = {2017},
  issue_date = {December 2017},
  publisher  = {Springer-Verlag},
  address    = {Berlin, Heidelberg},
  volume     = {33},
  number     = {12},
  issn       = {0178-2789},
  url        = {https://doi.org/10.1007/s00371-016-1305-1},
  doi        = {10.1007/s00371-016-1305-1},
  abstract   = {Under foggy or hazy weather conditions, the visibility and color fidelity of outdoor images are prone to degradation. Hazy images can be the cause of serious errors in many computer vision systems. Consequently, image haze removal has practical significance for real-world applications. In this study, we first analyze the inherent weaknesses of the atmospheric scattering model and propose an improvement to address those weaknesses. Then, we present a fast image haze removal algorithm based on the improved model. In our proposed method, the input image is partitioned into several scenes based on the haze thickness. Next, averaging and erosion operations calculate the rough scene luminance map in a scene-wise manner. We obtain the rough scene transmission map by maximizing the contrast in each scene and then develop a way to gently remove the haze using an adaptive method for adjusting scene transmission based on scene features. In addition, we propose a guided total variation model for edge optimization, so as to prevent from the block effect as well as to eliminate the negative effect from the wrong scene segmentation results. The experimental results demonstrate that our method is effective in solving a series of common problems, including uneven illuminance, overenhanced and oversaturated images, and so forth. Moreover, our method outperforms most current dehazing algorithms in terms of visual effects, universality, and processing speed.},
  journal    = {Vis. Comput.},
  month      = dec,
  pages      = {1613–1625},
  numpages   = {13},
  keywords   = {Atmospheric scattering model, Guided total variation model, Scene segmentation, Single image dehazing}
}
@misc{liu2019genericmodelagnosticconvolutionalneural,
  title         = {Generic Model-Agnostic Convolutional Neural Network for Single Image Dehazing},
  author        = {Zheng Liu and Botao Xiao and Muhammad Alrabeiah and Keyan Wang and Jun Chen},
  year          = {2019},
  eprint        = {1810.02862},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1810.02862}
}

@article{he2011,
  author  = {He, Kaiming and Sun, Jian and Tang, Xiaoou},
  year    = {2011},
  month   = {01},
  pages   = {2341-2353},
  title   = {Single Image Haze Removal Using Dark Channel Prior.},
  volume  = {33},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  doi     = {10.1109/CVPRW.2009.5206515}
}
@article{1284395,
  author   = {Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal  = {IEEE Transactions on Image Processing},
  title    = {Image quality assessment: from error visibility to structural similarity},
  year     = {2004},
  volume   = {13},
  number   = {4},
  pages    = {600-612},
  keywords = {Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi      = {10.1109/TIP.2003.819861}
}
@inproceedings{mss,
  author  = {Wang, Z. and Simoncelli, Eero and Bovik, Alan},
  year    = {2003},
  month   = {12},
  pages   = {1398 - 1402 Vol.2},
  title   = {Multiscale structural similarity for image quality assessment},
  volume  = {2},
  isbn    = {0-7803-8104-1},
  journal = {Conference Record of the Asilomar Conference on Signals, Systems and Computers},
  doi     = {10.1109/ACSSC.2003.1292216}
}

@article{ABDELSALAMNASR2017399,
  title    = {Multi-scale structural similarity index for motion detection},
  journal  = {Journal of King Saud University - Computer and Information Sciences},
  volume   = {29},
  number   = {3},
  pages    = {399-409},
  year     = {2017},
  issn     = {1319-1578},
  doi      = {https://doi.org/10.1016/j.jksuci.2016.02.004},
  url      = {https://www.sciencedirect.com/science/article/pii/S1319157816300088},
  author   = {M. {Abdel-Salam Nasr} and Mohammed F. AlRahmawy and A.S. Tolba},
  keywords = {Motion detection, Multi-scale structural similarity index, Dynamic template matching},
  abstract = {The most recent approach for measuring the image quality is the structural similarity index (SSI). This paper presents a novel algorithm based on the multi-scale structural similarity index for motion detection (MS-SSIM) in videos. The MS-SSIM approach is based on modeling of image luminance, contrast and structure at multiple scales. The MS-SSIM has resulted in much better performance than the single scale SSI approach but at the cost of relatively lower processing speed. The major advantages of the presented algorithm are both: the higher detection accuracy and the quasi real-time processing speed.}
}

@article{Song_2023,
  title     = {Vision Transformers for Single Image Dehazing},
  volume    = {32},
  issn      = {1941-0042},
  url       = {http://dx.doi.org/10.1109/TIP.2023.3256763},
  doi       = {10.1109/tip.2023.3256763},
  journal   = {IEEE Transactions on Image Processing},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Song, Yuda and He, Zhuqing and Qian, Hui and Du, Xin},
  year      = {2023},
  pages     = {1927–1941}
}
@inproceedings{ren2016,
  author    = {Ren, Wenqi
               and Liu, Si
               and Zhang, Hua
               and Pan, Jinshan
               and Cao, Xiaochun
               and Yang, Ming-Hsuan},
  editor    = {Leibe, Bastian
               and Matas, Jiri
               and Sebe, Nicu
               and Welling, Max},
  title     = {Single Image Dehazing via Multi-scale Convolutional Neural Networks},
  booktitle = {Computer Vision -- ECCV 2016},
  year      = {2016},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {154--169},
  abstract  = {The performance of existing image dehazing methods is limited by hand-designed features, such as the dark channel, color disparity and maximum contrast, with complex fusion schemes. In this paper, we propose a multi-scale deep neural network for single-image dehazing by learning the mapping between hazy images and their corresponding transmission maps. The proposed algorithm consists of a coarse-scale net which predicts a holistic transmission map based on the entire image, and a fine-scale net which refines results locally. To train the multi-scale deep network, we synthesize a dataset comprised of hazy images and corresponding transmission maps based on the NYU Depth dataset. Extensive experiments demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods on both synthetic and real-world images in terms of quality and speed.},
  isbn      = {978-3-319-46475-6}
}

@misc{chen2018gatedcontextaggregationnetwork,
  title         = {Gated Context Aggregation Network for Image Dehazing and Deraining},
  author        = {Dongdong Chen and Mingming He and Qingnan Fan and Jing Liao and Liheng Zhang and Dongdong Hou and Lu Yuan and Gang Hua},
  year          = {2018},
  eprint        = {1811.08747},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1811.08747}
}
@misc{tong2024hazeawareattentionnetworksingleimage,
  title         = {Haze-Aware Attention Network for Single-Image Dehazing},
  author        = {Lihan Tong and Yun Liu and Weijia Li and Liyuan Chen and Erkang Chen},
  year          = {2024},
  eprint        = {2407.11505},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2407.11505}
}
@misc{goel2022itsrawaudiogeneration,
  title         = {It's Raw! Audio Generation with State-Space Models},
  author        = {Karan Goel and Albert Gu and Chris Donahue and Christopher Ré},
  year          = {2022},
  eprint        = {2202.09729},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SD},
  url           = {https://arxiv.org/abs/2202.09729}
}

@misc{nguyen2022s4ndmodelingimagesvideos,
  title         = {S4ND: Modeling Images and Videos as Multidimensional Signals Using State Spaces},
  author        = {Eric Nguyen and Karan Goel and Albert Gu and Gordon W. Downs and Preey Shah and Tri Dao and Stephen A. Baccus and Christopher Ré},
  year          = {2022},
  eprint        = {2210.06583},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2210.06583}
}

@misc{islam2023longmovieclipclassification,
  title         = {Long Movie Clip Classification with State-Space Video Models},
  author        = {Md Mohaiminul Islam and Gedas Bertasius},
  year          = {2023},
  eprint        = {2204.01692},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2204.01692}
}

@misc{dosovitskiy2021imageworth16x16words,
  title         = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author        = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  year          = {2021},
  eprint        = {2010.11929},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2010.11929}
}

@misc{liu2021swintransformerhierarchicalvision,
  title         = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author        = {Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
  year          = {2021},
  eprint        = {2103.14030},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2103.14030}
}
@misc{ma2024umambaenhancinglongrangedependency,
  title         = {U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation},
  author        = {Jun Ma and Feifei Li and Bo Wang},
  year          = {2024},
  eprint        = {2401.04722},
  archiveprefix = {arXiv},
  primaryclass  = {eess.IV},
  url           = {https://arxiv.org/abs/2401.04722}
}

@misc{wang2024mambaunetunetlikepurevisual,
  title         = {Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation},
  author        = {Ziyang Wang and Jian-Qing Zheng and Yichi Zhang and Ge Cui and Lei Li},
  year          = {2024},
  eprint        = {2402.05079},
  archiveprefix = {arXiv},
  primaryclass  = {eess.IV},
  url           = {https://arxiv.org/abs/2402.05079}
}

@misc{zheng2024ushapedvisionmambasingle,
  title         = {U-shaped Vision Mamba for Single Image Dehazing},
  author        = {Zhuoran Zheng and Chen Wu},
  year          = {2024},
  eprint        = {2402.04139},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2402.04139}
}

@misc{nilsson2020understandingssim,
  title         = {Understanding SSIM},
  author        = {Jim Nilsson and Tomas Akenine-Möller},
  year          = {2020},
  eprint        = {2006.13846},
  archiveprefix = {arXiv},
  primaryclass  = {eess.IV},
  url           = {https://arxiv.org/abs/2006.13846}
}

@article{5567108,
  author   = {He, Kaiming and Sun, Jian and Tang, Xiaoou},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title    = {Single Image Haze Removal Using Dark Channel Prior},
  year     = {2011},
  volume   = {33},
  number   = {12},
  pages    = {2341-2353},
  keywords = {Image color analysis;Image restoration;Atmospheric modeling;Channel estimation;Dehaze;defog;image restoration;depth estimation.},
  doi      = {10.1109/TPAMI.2010.168}
}
@inproceedings{7271737,
  author    = {Marques, Francisco and Lourenço, André and Mendonça, Ricardo and Pinto, Eduardo and Rodrigues, Paulo and Santana, Pedro and Barata, José},
  booktitle = {OCEANS 2015 - Genova},
  title     = {A critical survey on marsupial robotic teams for environmental monitoring of water bodies},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {1-6},
  keywords  = {Robot sensing systems;Vehicles;Robot kinematics;Environmental monitoring;Sea surface},
  doi       = {10.1109/OCEANS-Genova.2015.7271737}
}
@article{7576656,
  author   = {Li, Sasa and Ho, K. C.},
  journal  = {IEEE Transactions on Wireless Communications},
  title    = {Accurate and Effective Localization of an Object in Large Equal Radius Scenario},
  year     = {2016},
  volume   = {15},
  number   = {12},
  pages    = {8273-8285},
  keywords = {Noise measurement;Position measurement;Closed-form solutions;Geology;Satellite communication;Object detection;Wireless communication;Large equal radius;localization;sensor position uncertainty;TDOA},
  doi      = {10.1109/TWC.2016.2613534}
}
@article{Rahmawati2024126142,
  author  = {Rahmawati, Lailia and Rustad, Supriadi and Marjuni, Aris and Soeleman, Mochammad Arief and Supriyanto, Catur and Shidik, Guruh Fajar},
  doi     = {10.2478/cait-2024-0039},
  url     = {https://doi.org/10.2478/cait-2024-0039},
  title   = {Transmission Map Refinement Using Laplacian Transform on Single Image Dehazing Based on Dark Channel Prior Approach},
  journal = {Cybernetics and Information Technologies},
  number  = {4},
  volume  = {24},
  year    = {2024},
  pages   = {126--142}
}
@article{Cai_2016,
  title     = {DehazeNet: An End-to-End System for Single Image Haze Removal},
  volume    = {25},
  issn      = {1941-0042},
  url       = {http://dx.doi.org/10.1109/TIP.2016.2598681},
  doi       = {10.1109/tip.2016.2598681},
  number    = {11},
  journal   = {IEEE Transactions on Image Processing},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Cai, Bolun and Xu, Xiangmin and Jia, Kui and Qing, Chunmei and Tao, Dacheng},
  year      = {2016},
  month     = nov,
  pages     = {5187–5198}
}
@inproceedings{8237773,
  author    = {Li, Boyi and Peng, Xiulian and Wang, Zhangyang and Xu, Jizheng and Feng, Dan},
  booktitle = {2017 IEEE International Conference on Computer Vision (ICCV)},
  title     = {AOD-Net: All-in-One Dehazing Network},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {4780-4788},
  keywords  = {Atmospheric modeling;Image restoration;Scattering;Computational modeling;Visualization;Estimation},
  doi       = {10.1109/ICCV.2017.511}
}
@article{QIN2024110,
  title    = {Single image dehazing based on multi-label graph cuts},
  journal  = {Pattern Recognition Letters},
  volume   = {185},
  pages    = {110-116},
  year     = {2024},
  issn     = {0167-8655},
  doi      = {https://doi.org/10.1016/j.patrec.2024.07.015},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167865524002186},
  author   = {Minshen Qin and Junzheng Jiang and Fang Zhou},
  keywords = {Image dehazing, Multi-label graph cuts, Transmission estimation},
  abstract = {Haze blurs image information and reduces the visibility of objects in the image, which seriously affects the performance of computer vision applications in a hazy environment. We propose an improved dehazing model based on multi-label graph cuts. A hazy image is modeled as an undirected graph. The multi-label graph cuts algorithm divides the image into subregions according to the functions of brightness and saturation. A subregion is selected to estimate atmospheric light based on saturation. Under the similarity of transmission in the same subregion, transmission is estimated by the distance between the pixel and atmospheric light in RGB space. Finally, the transmission map is regularized to recover a haze-free image. Experiments in different scenarios demonstrate the effectiveness of the proposed method than the state-of-the-art methods.}
}

@article{cmc-202202-3339,
  author   = {Fayadh Alenezi},
  title    = {Image Dehazing Based on Pixel Guided CNN with PAM via Graph Cut},
  journal  = {Computers, Materials \& Continua},
  volume   = {71},
  year     = {2022},
  number   = {2},
  pages    = {3425--3443},
  url      = {http://www.techscience.com/cmc/v71n2/45866},
  issn     = {1546-2226},
  abstract = {Image dehazing is still an open research topic that has been undergoing a lot of development, especially with the renewed interest in machine learning-based methods. A major challenge of the existing dehazing methods is the estimation of transmittance, which is the key element of haze-affected imaging models. Conventional methods are based on a set of assumptions that reduce the solution search space. However, the multiplication of these assumptions tends to restrict the solutions to particular cases that cannot account for the reality of the observed image. In this paper we reduce the number of simplified hypotheses in order to attain a more plausible and realistic solution by exploiting a priori knowledge of the ground truth in the proposed method. The proposed method relies on pixel information between the ground truth and haze image to reduce these assumptions. This is achieved by using ground truth and haze image to find the geometric-pixel information through a guided Convolution Neural Networks (CNNs) with a Parallax Attention Mechanism (PAM). It uses the differential pixel-based variance in order to estimate transmittance. The pixel variance uses local and global patches between the assumed ground truth and haze image to refine the transmission map. The transmission map is also improved based on improved Markov random field (MRF) energy functions. We used different images to test the proposed algorithm. The entropy value of the proposed method was 7.43 and 7.39, a percent increase of  and , respectively, compared to the best existing results. The increment is similar in other performance quality metrics and this validate its superiority compared to other existing methods in terms of key image quality evaluation metrics. The proposed approach's drawback, an over-reliance on real ground truth images, is also investigated. The proposed method show more details hence yields better images than those from the existing state-of-the-art-methods.},
  doi      = {10.32604/cmc.2022.023339}
}



